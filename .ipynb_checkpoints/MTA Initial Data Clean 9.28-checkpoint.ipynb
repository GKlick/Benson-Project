{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2018/9/27 Updates\n",
    "\n",
    "Changes\n",
    "1. More columns convertions to proper datatypes\n",
    "2. New dataframe created for future manipulations\n",
    "3. Entry and exit tracking numbers combined for each turnstile reporting\n",
    "4. Hours elapsed since previous reporting tracked\n",
    "5. Passenger per hour per turntiles tracked\n",
    "\n",
    "\n",
    "Next steps:\n",
    "2. Rate for each station by hour (groupby station, day, hour)\n",
    "\n",
    "\n",
    "ID explained \n",
    "Station then Unit(think enterance maybe) then CA(booth) then SCP(turnstyle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T18:00:40.809715Z",
     "start_time": "2018-09-29T18:00:39.229350Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T18:00:40.853329Z",
     "start_time": "2018-09-29T18:00:40.848345Z"
    }
   },
   "outputs": [],
   "source": [
    "#changes float views from scientific to ???? (what would you call the other view?)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load April - July, 2017 & 2018 MTA Turntile data\n",
    "#time intensive block\n",
    "df = pd.read_csv('/Users/GabeKlick/Downloads/turnstile_recordings_summer_2017_2018_clean.csv', index_col = 'Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#exit column has a few misplaced chars preventing the column from being int values\n",
    "#this block removes the chars and converts columns to int64\n",
    "\n",
    "#apply regex statement to ensure only numbers in the column\n",
    "def only_num(col):\n",
    "    return re.findall('(\\d)', col)\n",
    "df.exits = df.exits.apply(lambda x: only_num(str(x)))\n",
    "\n",
    "#the regex statment returns a list a numbers for each value\n",
    "#join list values to single string items of numbers\n",
    "df.exits = df.exits.apply(lambda x: ''.join(x))\n",
    "\n",
    "#convert str to int64\n",
    "df.exits = df.exits.apply(lambda x: int(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped df.date conversion - which was a speparate from the date_time combine conversion\n",
    "\n",
    "#combine and convert date,time column from str to datetime\n",
    "#time intensive block, run then take 5\n",
    "\n",
    "#df.date = pd.to_datetime(df.date_time, infer_datetime_format= True)\n",
    "df.time = pd.to_datetime(df.date + ' ' + df.time)\n",
    "\n",
    "#rename to showcase the new time feature in the column\n",
    "df.rename({'time': 'date_time'}, axis = 'columns', inplace = True)\n",
    "\n",
    "#removes the now date time column\n",
    "df.drop(columns = ['date'], inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure that date_time is increasing in chronical order\n",
    "#this is helpful later when grouping by turnstiles and station\n",
    "df = df.sort_values(by = 'date_time', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pickle for quicker processing time\n",
    "df.to_pickle('date_formatted_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T18:00:47.153031Z",
     "start_time": "2018-09-29T18:00:44.237554Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('/Users/GabeKlick/Desktop//date_formatted_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove dates before May and after August\n",
    "df = df[(df.date_time.dt.month != 4) & (df.date_time.dt.month != 8)].reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-29T18:01:05.115958Z",
     "start_time": "2018-09-29T18:01:04.837492Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/GabeKlick/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>c_a</th>\n",
       "      <th>unit</th>\n",
       "      <th>scp</th>\n",
       "      <th>station</th>\n",
       "      <th>linename</th>\n",
       "      <th>division</th>\n",
       "      <th>date</th>\n",
       "      <th>date_time</th>\n",
       "      <th>desc</th>\n",
       "      <th>entries</th>\n",
       "      <th>exits</th>\n",
       "      <th>Index</th>\n",
       "      <th>num_entries</th>\n",
       "      <th>num_exits</th>\n",
       "      <th>time_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-05-01 00:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6159107</td>\n",
       "      <td>2085842</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-05-01 04:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6159116</td>\n",
       "      <td>2085849</td>\n",
       "      <td>1</td>\n",
       "      <td>9.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-05-01 08:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6159166</td>\n",
       "      <td>2085976</td>\n",
       "      <td>2</td>\n",
       "      <td>50.000</td>\n",
       "      <td>127.000</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-05-01 12:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6159331</td>\n",
       "      <td>2086218</td>\n",
       "      <td>3</td>\n",
       "      <td>165.000</td>\n",
       "      <td>242.000</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>A002</td>\n",
       "      <td>R051</td>\n",
       "      <td>02-00-00</td>\n",
       "      <td>59 ST</td>\n",
       "      <td>NQR456W</td>\n",
       "      <td>BMT</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2017-05-01 16:00:00</td>\n",
       "      <td>REGULAR</td>\n",
       "      <td>6159595</td>\n",
       "      <td>2086299</td>\n",
       "      <td>4</td>\n",
       "      <td>264.000</td>\n",
       "      <td>81.000</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   c_a  unit       scp station linename division       date  \\\n",
       "0     12  A002  R051  02-00-00   59 ST  NQR456W      BMT 2017-05-01   \n",
       "1     13  A002  R051  02-00-00   59 ST  NQR456W      BMT 2017-05-01   \n",
       "2     14  A002  R051  02-00-00   59 ST  NQR456W      BMT 2017-05-01   \n",
       "3     15  A002  R051  02-00-00   59 ST  NQR456W      BMT 2017-05-01   \n",
       "4     16  A002  R051  02-00-00   59 ST  NQR456W      BMT 2017-05-01   \n",
       "\n",
       "            date_time     desc  entries    exits  Index  num_entries  \\\n",
       "0 2017-05-01 00:00:00  REGULAR  6159107  2085842      0          nan   \n",
       "1 2017-05-01 04:00:00  REGULAR  6159116  2085849      1        9.000   \n",
       "2 2017-05-01 08:00:00  REGULAR  6159166  2085976      2       50.000   \n",
       "3 2017-05-01 12:00:00  REGULAR  6159331  2086218      3      165.000   \n",
       "4 2017-05-01 16:00:00  REGULAR  6159595  2086299      4      264.000   \n",
       "\n",
       "   num_exits time_elapsed  \n",
       "0        nan          NaT  \n",
       "1      7.000     04:00:00  \n",
       "2    127.000     04:00:00  \n",
       "3    242.000     04:00:00  \n",
       "4     81.000     04:00:00  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#replace typo in c_a column\n",
    "df[df['c_a'] == ' \"A002']['c_a'] = 'A002'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grouping by turnstile id (station, unit, c_a, scp), find the difference between consecutive data points\n",
    "#for each individual turnstile. This method is applied to both the exit, entry, and date_time for each observation\n",
    "difference_of_entries = df.groupby(['station', 'unit', 'c_a', 'scp'])['entries'].apply(lambda x: x- x.shift(1))\n",
    "difference_of_exits = df.groupby(['station', 'unit', 'c_a', 'scp'])['exits'].apply(lambda x: x- x.shift(1))\n",
    "time_elapsed_series = df.groupby(['station', 'unit', 'c_a', 'scp'])['date_time'].apply(lambda x: x- x.shift(1))\n",
    "\n",
    "#these 3 series are ardded to a temp data frame that will be merged to the main dataframe\n",
    "temp_df = pd.DataFrame({'Index': df.index, 'num_entries': difference_of_entries, 'num_exits': difference_of_exits, 'time_elapsed': time_elapsed_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#time intensive, run then take 5\n",
    "#merge the main and temp df on the index column\n",
    "df = pd.concat([df, temp_df], axis = 1, join = 'outer')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed all rows where the time elapsed was greater than 60 days\n",
    "#This drops 1.8% of the data\n",
    "df = df[df['time_elapsed'].dt.days <= 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed rows with negative time elapses.\n",
    "# needed to be greated than OR equal to because all time elapses within 24 hours are 0 or dt.days\n",
    "#This removed 0% of the data\n",
    "df = df[df['time_elapsed'].dt.days >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This should later be moved to a later section, where the columns are defined\n",
    "'''\n",
    "Create a variable that tracks the rate of passengers for each turnstile per hour\n",
    "\n",
    "Numerator: add the num enteries/exit per observation that was found before the merge.\n",
    "This gives total foot traffic per turnstile per observation\n",
    "\n",
    "Denominator: time elapsed provides the difference between each observation for each turnstile.\n",
    "This observation can be pulled by full days (year,mont, day converted to day) \n",
    "and partial day (hour, min, seconds to seconds).\n",
    "For each observation the full and partial day info is converted to seconds (24hours*60min*60sec = 86400seconds)\n",
    "then converted back to hour format (60min*60seconds = 3600 seconds)\n",
    "\n",
    "'''\n",
    "df['passengers_per_hour_per_turnstile'] = (df.num_entries + df.num_exits) \\\n",
    "/(((df.time_elapsed.dt.days * 86400) + (df.time_elapsed.dt.seconds))/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove outliers for passengers per hour per turnstile that are greater than 1000\n",
    "#this removes .01% of the data\n",
    "df = df[df['passengers_per_hour_per_turnstile'] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created a new dataframe grouping station by date, and turnstile\n",
    "turnstile_df = df[['station', 'date_time','num_entries', 'num_exits', 'time_elapsed']]\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed all rows where the num_entries OR the num_exits was less than or equal to 0\n",
    "#logically, turnstiles should alway be increasing throughout time. However, due to errors in the systems\n",
    "#such as resets there can be cases of negative values\n",
    "\n",
    "#This removes 16.65% of the data\n",
    "turnstile_df = turnstile_df[(turnstile_df['num_entries'] > 0) & (turnstile_df['num_exits'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see above for long block using these equations before defining variable\n",
    "#variable should have a different name, total passengers per turnstiles or something\n",
    "\n",
    "# combine total passengers for each turnstile reporting\n",
    "turnstile_df['total_passengers'] = turnstile_df.num_entries + turnstile_df.num_exits\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see above for long block using these equations before defining variable\n",
    "\n",
    "\n",
    "#create column tracking total hours passed for each turnstile reporting\n",
    "turnstile_df['hours_elapsed'] = (((df['time_elapsed'].dt.days * 86400) + (df['time_elapsed'].dt.seconds)))/3600\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the data frame\n",
    "turnstile_df.to_pickle('turnstile_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# aggregations for new dataframe 'see below'\n",
    "#grouping by station and time segment,\n",
    "#sum across turnstiles in stations\n",
    "#sum the hours elapsed for each grouping\n",
    "#count the number of turnstiles in each grouping\n",
    "#the sum of hours elapsed and turnstiles count should logically divide to the time elapsed\n",
    "aggregations = {\n",
    "    'total_passengers': 'sum',\n",
    "    'hours_elapsed': 'sum',\n",
    "    'num_entries': 'count'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new dataframe by station by date\n",
    "#apply aggregations from above\n",
    "date_df = turnstile_df.groupby(('station','date_time')).agg(aggregations).reset_index()\n",
    "date_df.rename({'hours_elapsed': 'turnstile_hours', 'num_entries': 'num_turnstiles'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these variables have been defined earlier, here we are rewriting\n",
    "#passengers per hour is total passengers per station (summed turnstiles totals)\n",
    "\n",
    "#for each turnstile reporting, finds the rate of passengers per hour\n",
    "date_df['hours_elapsed'] = (date_df['turnstile_hours']/date_df['num_turnstiles'])\n",
    "date_df['passengers_per_hour'] = date_df.total_passengers/date_df.hours_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "aggregations = {\n",
    "    'total_passengers': 'sum',\n",
    "    'num_turnstiles': 'count',\n",
    "    'hours_elapsed': 'sum'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe for grouping stations together, irrespective of date\n",
    "station_df = date_df.groupby(('station')).agg(aggregations).reset_index()\n",
    "station_df['passengers_per_hour'] = station_df.total_passengers/station_df.hours_elapsed\n",
    "station_df.rename({'hours_elapsed': 'station_hours'}, axis = 1, inplace = True)\n",
    "station_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
