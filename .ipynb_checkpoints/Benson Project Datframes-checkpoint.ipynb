{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T13:07:30.613246Z",
     "start_time": "2018-10-01T13:07:30.304968Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T13:07:30.752196Z",
     "start_time": "2018-10-01T13:07:30.748256Z"
    }
   },
   "outputs": [],
   "source": [
    "#changes float views from scientific\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-01T13:07:34.830792Z",
     "start_time": "2018-10-01T13:07:34.281085Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load April - July, 2017 & 2018 MTA Turntile data\n",
    "#time intensive block\n",
    "df = pd.read_csv('/Users/charlieyaris/turnstile_recordings_summer_2017_2018_clean.csv', index_col = 'Unnamed: 0')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#exit column has a few misplaced chars preventing the column from being int values\n",
    "#this block removes the chars and converts columns to int64\n",
    "\n",
    "#apply regex statement to ensure only numbers in the column\n",
    "def only_num(col):\n",
    "    return re.findall('(\\d)', col)\n",
    "df.exits = df.exits.apply(lambda x: only_num(str(x)))\n",
    "\n",
    "#the regex statment returns a list a numbers for each value\n",
    "#join list values to single string items of numbers\n",
    "df.exits = df.exits.apply(lambda x: ''.join(x))\n",
    "\n",
    "#convert str to int64\n",
    "df.exits = df.exits.apply(lambda x: int(x))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropped df.date conversion - which was a speparate from the date_time combine conversion\n",
    "\n",
    "#combine and convert date,time column from str to datetime\n",
    "#time intensive block, run then take 5\n",
    "\n",
    "df.time = pd.to_datetime(df.date + ' ' + df.time)\n",
    "\n",
    "#rename to showcase the new time feature in the column\n",
    "df.rename({'time': 'date_time'}, axis = 'columns', inplace = True)\n",
    "\n",
    "#removes the now date time column\n",
    "df.drop(columns = ['date'], inplace = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensure that date_time is increasing in chronical order\n",
    "#this is helpful later when grouping by turnstiles and station\n",
    "df = df.sort_values(by = 'date_time', ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create pickle for quicker processing time\n",
    "df.to_pickle('date_formatted_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('date_formatted_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove dates before May and after August\n",
    "df = df[(df.date_time.dt.month != 4) & (df.date_time.dt.month != 8)].reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['station', 'unit', 'c_a', 'scp'])['entries'].apply(lambda x: x - x.shift(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace typo in c_a column\n",
    "df.loc[df['c_a'] == ' \"A002', 'c_a'] = 'A002'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping by turnstile id (station, unit, c_a, scp), find the difference between consecutive data points\n",
    "# for each individual turnstile. This method is applied to both the exit, entry, and date_time for each observation\n",
    "entries_difference_series = df.groupby(['station', 'unit', 'c_a', 'scp'])['entries'].apply(lambda x: x - x.shift(1))\n",
    "exits_difference_series = df.groupby(['station', 'unit', 'c_a', 'scp'])['exits'].apply(lambda x: x - x.shift(1))\n",
    "time_elapsed_series = df.groupby(['station', 'unit', 'c_a', 'scp'])['date_time'].apply(lambda x: x - x.shift(1))\n",
    "\n",
    "#these 3 series are ardded to a temp data frame that will be merged to the main dataframe\n",
    "temp_df = pd.DataFrame({'Index': df.index, 'num_entries': entries_difference_series, 'num_exits': exits_difference_series, 'time_elapsed': time_elapsed_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show temp df\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# creating a new dataframe for grouping at the turnstile level\n",
    "# time intensive, run then take 5\n",
    "# merge the main and temp df on the index column\n",
    "turnstile_df = pd.concat([df, temp_df], axis = 1, join = 'outer')\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed all rows where the time elapsed was greater than 60 days\n",
    "#This drops a negligible amount of date (< .01%)\n",
    "turnstile_df = turnstile_df[turnstile_df['time_elapsed'].dt.days <= 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed rows with negative time elapses.\n",
    "# needs to be greated than OR equal to because all time elapses within 24 hours are 0 or dt.days\n",
    "#This drops a negligible amount of date (< .01%)\n",
    "turnstile_df = turnstile_df[turnstile_df['time_elapsed'].dt.days >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a variable that tracks the rate of passengers for each turnstile per hour\n",
    "\n",
    "Numerator: add the num enteries/exit per observation that was found before the merge.\n",
    "This gives total foot traffic per turnstile per observation\n",
    "\n",
    "Denominator: time elapsed provides the difference between each observation for each turnstile.\n",
    "This observation can be pulled by full days (year,mont, day converted to day) \n",
    "and partial day (hour, min, seconds to seconds).\n",
    "For each observation the full and partial day info is converted to seconds (24hours*60min*60sec = 86400seconds)\n",
    "then converted back to hour format (60min*60seconds = 3600 seconds)''\n",
    "\n",
    "'''\n",
    "turnstile_df['passengers_per_hour_per_turnstile'] = (turnstile_df.num_entries + turnstile_df.num_exits) \\\n",
    "/(((turnstile_df.time_elapsed.dt.days * 86400) + (turnstile_df.time_elapsed.dt.seconds))/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove outliers for passengers per hour per turnstile that are greater than 1000\n",
    "# this removes .01% of the data\n",
    "turnstile_df = turnstile_df[turnstile_df['passengers_per_hour_per_turnstile'] < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed all rows where the num_entries OR the num_exits was less than or equal to 0\n",
    "# logically, turnstiles should alway be increasing throughout time. However, due to errors in the systems\n",
    "# such as resets there can be cases of negative values\n",
    "\n",
    "# This removes 16.65% of the data\n",
    "turnstile_df = turnstile_df[(turnstile_df['num_entries'] > 0) & (turnstile_df['num_exits'] > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine total passengers for each turnstile reporting\n",
    "turnstile_df['total_passengers'] = turnstile_df.num_entries + turnstile_df.num_exits\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''time elapsed provides the difference between each observation for each turnstile.\n",
    "This observation can be pulled by full days (year,mont, day converted to day) \n",
    "and partial day (hour, min, seconds to seconds).\n",
    "For each observation the full and partial day info is converted to seconds (24hours*60min*60sec = 86400seconds)\n",
    "then converted back to hour format (60min*60seconds = 3600 seconds) '''\n",
    "\n",
    "#create column tracking total hours passed for each turnstile reporting\n",
    "turnstile_df['hours_elapsed'] = (((turnstile_df['time_elapsed'].dt.days * 86400) + (turnstile_df['time_elapsed'].dt.seconds)))/3600\n",
    "turnstile_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the data frame\n",
    "turnstile_df.to_pickle('turnstile_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickle\n",
    "turnstile_df = pd.read_pickle('turnstile_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# aggregations for new dataframe 'see below'\n",
    "#grouping by station and time segment,\n",
    "#sum across turnstiles in stations\n",
    "#sum the hours elapsed for each grouping\n",
    "#count the number of turnstiles in each grouping\n",
    "#the sum of hours elapsed and turnstiles count should logically divide to the time elapsed\n",
    "aggregations = {\n",
    "    'total_passengers': 'sum',\n",
    "    'hours_elapsed': 'sum',\n",
    "    'num_entries': 'count'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create a new dataframe by station by date\n",
    "#apply aggregations from above\n",
    "date_df = turnstile_df.groupby(('station','date_time')).agg(aggregations).reset_index()\n",
    "date_df.rename({'hours_elapsed': 'turnstile_hours', 'num_entries': 'num_turnstiles'}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#passengers per hour is total passengers per station (summed turnstiles totals)\n",
    "\n",
    "#for each turnstile reporting, finds the rate of passengers per hour\n",
    "date_df['hours_elapsed'] = (date_df['turnstile_hours']/date_df['num_turnstiles'])\n",
    "date_df['passengers_per_hour'] = date_df.total_passengers/date_df.hours_elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the data frame\n",
    "date_df.to_pickle('date_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from pickle\n",
    "date_df = pd.read_pickle('date_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create aggregation for new data frame.\n",
    "Sum total passengers across turnstile within a station\n",
    "Sum turnstile recordings within each time segment. This is used as a 'check' column.\n",
    "Sum hours elapsed with each time segment, This is used as a 'check' against the turnstile recordings\n",
    "\n",
    "'''\n",
    "\n",
    "aggregations = {\n",
    "    'total_passengers': 'sum',\n",
    "    'num_turnstiles': 'sum',\n",
    "    'date_time': 'count',\n",
    "    'hours_elapsed': 'sum'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dateframe off total passangers per station\n",
    "station_df = date_df.groupby(('station')).agg(aggregations).reset_index()\n",
    "\n",
    "#create column giving the average rate of passangers at a station for all hours elapsed\n",
    "station_df['passengers_per_hour'] = station_df.total_passengers/station_df.hours_elapsed\n",
    "station_df.rename({'hours_elapsed': 'station_hours', 'num_turnstiles': 'num_observations', 'date_time': 'date_time_count'}, axis = 1, inplace = True)\n",
    "\n",
    "#create a column tracking the number of recordings for a station divided by hours elapsed in dataset\n",
    "station_df['num_turnstiles'] = station_df.num_observations/station_df.date_time_count\n",
    "\n",
    "station_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle the data frame\n",
    "station_df.to_pickle('station_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = pd.read_pickle('station_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
